{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Player_By_Game Data from Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in all the partial data pieces\n",
    "\n",
    "df1 = pd.read_csv('../data/player_boxscores/offset_0-200000.csv')\n",
    "df2 = pd.read_csv('../data/player_boxscores/offset_200000-300000.csv')\n",
    "df3 = pd.read_csv('../data/player_boxscores/offset_300000-475000.csv')\n",
    "df4 = pd.read_csv('../data/player_boxscores/offset_475000-550000.csv')\n",
    "df5 = pd.read_csv('../data/player_boxscores/offset_550000-600000.csv')\n",
    "df6 = pd.read_csv('../data/player_boxscores/offset_600000-725000.csv')\n",
    "df7 = pd.read_csv('../data/player_boxscores/offset_725000-909000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate all the segmented data into one dataframe\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check starting shape\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA And Cleaning of Player_By_Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop these columns because they are derived explicity from existing features\n",
    "df.drop(['fg_pct', 'fg2_pct', 'fg3_pct', 'ft_pct', 'trb'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop erroneous column\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we don't know whether they started or not, chances are they did not. We'll set np.nan \n",
    "# of 'gs' to 0.\n",
    "df['gs'] = df['gs'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and drop duplicated rows, probably resulting from scraping overlap\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will be bringing in a lot of opponent data as features, so not knowing the opp_id is \n",
    "# useless to us. So let's drop the np.nan values in opp_id\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check resulting shape. We still have 96% of our original rows. Pretty good\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert date_game to datetime type\n",
    "\n",
    "df['date_game'] = pd.to_datetime(df['date_game'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a year and month feature\n",
    "\n",
    "df['year'] = df['date_game'].map(lambda x: x.year)\n",
    "df['month'] = df['date_game'].map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea of timeframe \n",
    "\n",
    "print(df['date_game'].min())\n",
    "print(df['date_game'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a 'season' feature, where the year it ended is defined as the season\n",
    "\n",
    "season_list = []\n",
    "for i in df['date_game']:\n",
    "    if i.month == 11 or i.month == 12:\n",
    "        season_list.append(i.year + 1)\n",
    "    else:\n",
    "        season_list.append(i.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['season'] = season_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Codify Win/Loss with 1/0\n",
    "df['W'] = df['game_result'].map(lambda x: 1 if x == 'W' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dummify position\n",
    "#df = pd.concat([df, pd.get_dummies(df['pos'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop game_result: We have one-hot encoded\n",
    "df.drop('game_result', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../data/player_boxscores_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in School Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "school_df = pd.read_csv('../data/schools.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player-by-Player Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.set_index(['player', 'date_game'], drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats = ['gs', 'mp', 'fg2', 'fg2a', 'fg3', 'fg3a', 'ft', 'fta','orb', 'drb', 'ast', \n",
    "         'stl', 'blk', 'tov', 'pf', 'pts', 'game_score', 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specifically needed for rolling mean and rolling median\n",
    "\n",
    "lookbacks = ['_3day_', '_10day_', '_30day_', '_60day_', '_90day_', '_120day_']\n",
    "\n",
    "metrics = ['mean', 'median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specifically needed for rolling mean and rolling median\n",
    "\n",
    "all_rolling = []\n",
    "\n",
    "for i in metrics:\n",
    "    for j in lookbacks:\n",
    "        for k in stats:\n",
    "            all_rolling.append(i+j+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There will be some noise introduced by players with same name (no unique id associated)\n",
    "players = df['player'].unique()\n",
    "len(players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats.append('date_game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "stamp = datetime.now()\n",
    "for player in players:\n",
    "    if count % 500 == 0:\n",
    "        diff_time = datetime.now() - stamp\n",
    "        stamp = datetime.now()\n",
    "        print('parsing...', count)\n",
    "        print('last parsing block took: ', (diff_time.seconds / 60), ' minutes')\n",
    "    player_df = df.loc[player][stats].sort_values('date_game')\n",
    "    \n",
    "    ewm_01 = player_df.drop('date_game', axis=1).ewm(alpha = 0.1, min_periods=1).mean().shift()\n",
    "    ewm_03 = player_df.drop('date_game', axis=1).ewm(alpha = 0.3, min_periods=1).mean().shift()\n",
    "    ewm_05 = player_df.drop('date_game', axis=1).ewm(alpha = 0.5, min_periods=1).mean().shift()\n",
    "    ewm_07 = player_df.drop('date_game', axis=1).ewm(alpha = 0.7, min_periods=1).mean().shift()\n",
    "    ewm_09 = player_df.drop('date_game', axis=1).ewm(alpha = 0.9, min_periods=1).mean().shift()\n",
    "    ewm_10 = player_df.drop('date_game', axis=1).ewm(alpha = 1.0, min_periods=1).mean().shift()\n",
    "    \n",
    "    this_df = pd.concat([ewm_01, ewm_03, ewm_05, ewm_07, ewm_09, ewm_10], axis=1)\n",
    "\n",
    "    this_df['player'] = player\n",
    "\n",
    "    this_df.to_csv('../data/player_ewm/'+player.replace(' ', '_')+'.csv')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player-by-Player Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (dirpath, dirnames, filenames) in os.walk('../data/player_ewm/'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = filenames # [:3] for testing\n",
    "\n",
    "with open('../data/player_ewm_df.csv', 'wb') as output:\n",
    "    for filename in f:\n",
    "        with open('../data/player_ewm/'+filename, 'rb') as _input:\n",
    "            for i, line in enumerate(_input):\n",
    "                if i == 0:\n",
    "                    continue       \n",
    "                #print(line) # for testing\n",
    "                output.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_ewm_df = pd.read_csv('../data/player_ewm_df.csv', skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats = pd.Series(stats)\n",
    "\n",
    "ewm_cols = []\n",
    "for i in ['01', '03', '05', '07', '09', '10']:\n",
    "    for j in stats.drop(18):\n",
    "        ewm_cols.append('ewm'+j+'_'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_cols.insert(0, 'date_game')\n",
    "ewm_cols.append('player')\n",
    "len(ewm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_ewm_df.columns = ewm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ewm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_ewm_df['date_game'] = pd.to_datetime(player_ewm_df['date_game'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_ewm_df.set_index(['player', 'date_game'], drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df = df.join(player_ewm_df, how='left', on=['player', 'date_game'], rsuffix='_right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player-by-Player Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ewm_cols.append('pts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial_df = joined_df[ewm_cols].drop(['date_game', 'player'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trial_df.drop('pts', axis=1)\n",
    "y = trial_df['pts']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_linreg = LinearRegression()\n",
    "player_linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_lr = cross_val_score(player_linreg, X_train, y_train, cv=5)\n",
    "score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_lr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to GroupBy to get Team Score Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_lr = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_preds = player_linreg.predict(temp_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df['player_preds'] = lr_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_actual = joined_df.groupby(['school_id', 'date_game']).sum()['pts']\n",
    "team_preds = joined_df.groupby(['school_id', 'date_game']).sum()['player_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(team_actual.shape)\n",
    "team_actual.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(team_preds.shape)\n",
    "team_preds.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(team_actual, team_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(team_actual, team_preds, alpha=0.2)\n",
    "plt.xlim(0,150)\n",
    "plt.ylim(0,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_rf = RandomForestRegressor(max_depth=2)\n",
    "player_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf = cross_val_score(player_rf, X_train, y_train, cv=5)\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rf.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to GroupBy to get Team Score Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df = df.groupby(['school_id', 'opp_id', 'date_game']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sum of 'game_started' flag and 'minutes_played' meaningless, so we can drop\n",
    "team_df.drop(['gs', 'mp', 'year', 'month', 'season'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df[(team_df['school_id']=='Nevada-Las Vegas') & (team_df['date_game'] == '2018-03-07')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df[(team_df['school_id']=='Air Force') & (team_df['date_game'] == '2017-12-06')].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP RUNNING THIS FUCKING CELL YOU FUCKING MORON, THIS SHIT TAKES FOREVER\n",
    "index_dict = {}\n",
    "for i in team_df.index:\n",
    "    row = team_df.loc[i]\n",
    "    try:\n",
    "        opp_index = team_df[(team_df['school_id']==row['opp_id']) & (team_df['date_game'] == row['date_game'])].index[0]\n",
    "    except:\n",
    "        opp_index = np.nan\n",
    "    index_dict[i] = opp_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_stats = ['fg', 'fga', 'fg2', 'fg2a', 'fg3', 'fg3a', 'ft', 'fta', 'orb', 'drb', 'ast', \n",
    "             'stl', 'blk', 'tov', 'pf', 'pts', 'game_score', 'W']\n",
    "\n",
    "team_opp_df = pd.DataFrame(columns=def_stats)\n",
    "\n",
    "count = 0\n",
    "for key in range(0,87171):\n",
    "    if count % 500 == 0:\n",
    "        print('parsed...', count)\n",
    "    try:\n",
    "        team_opp_df = team_opp_df.append(team_df.loc[index_dict[key]][def_stats])\n",
    "    except:\n",
    "        team_opp_df.append({'fg':np.nan, 'fga':np.nan, 'fg2':np.nan, 'fg2a':np.nan, \n",
    "                            'fg3':np.nan, 'fg3a':np.nan, 'ft':np.nan, 'fta':np.nan, \n",
    "                            'orb':np.nan, 'drb':np.nan, 'ast':np.nan, 'stl':np.nan, \n",
    "                            'blk':np.nan, 'tov':np.nan, 'pf':np.nan, 'pts':np.nan, \n",
    "                            'game_score':np.nan, 'W':np.nan}, ignore_index=True)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_opp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_df_cols = ['def_fg', 'def_fga', 'def_fg2', 'def_fg2a', 'def_fg3', 'def_fg3a', 'def_ft', \n",
    "               'def_fta', 'def_orb', 'def_drb', 'def_ast', 'def_stl', 'def_blk', 'def_tov', \n",
    "               'def_pf', 'def_pts', 'def_game_score', 'def_W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_opp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df['mp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "stamp = datetime.now()\n",
    "for player in players:\n",
    "    if count % 500 == 0:\n",
    "        diff_time = datetime.now() - stamp\n",
    "        stamp = datetime.now()\n",
    "        print('parsing...', count)\n",
    "        print('last parsing block took: ', (diff_time.seconds / 60), ' minutes')\n",
    "    player_df = df.loc[player][stats].sort_values('date_game')\n",
    "\n",
    "    mean_3day = player_df.drop('date_game', axis=1).rolling(window=3, center=False, min_periods=1).mean().shift()\n",
    "    mean_10day = player_df.drop('date_game', axis=1).rolling(window=10, center=False, min_periods=1).mean().shift()\n",
    "    mean_30day = player_df.drop('date_game', axis=1).rolling(window=30, center=False, min_periods=1).mean().shift()\n",
    "    mean_60day = player_df.drop('date_game', axis=1).rolling(window=60, center=False, min_periods=1).mean().shift()\n",
    "    mean_90day = player_df.drop('date_game', axis=1).rolling(window=90, center=False, min_periods=1).mean().shift()\n",
    "    mean_120day = player_df.drop('date_game', axis=1).rolling(window=120, center=False, min_periods=1).mean().shift()\n",
    "\n",
    "    #median_3day = player_df.drop('date_game', axis=1).rolling(window=3, center=False, min_periods=1).median()\n",
    "    #median_10day = player_df.drop('date_game', axis=1).rolling(window=10, center=False, min_periods=1).median()\n",
    "    #median_30day = player_df.drop('date_game', axis=1).rolling(window=30, center=False, min_periods=1).median()\n",
    "    #median_60day = player_df.drop('date_game', axis=1).rolling(window=60, center=False, min_periods=1).median()\n",
    "    #median_90day = player_df.drop('date_game', axis=1).rolling(window=90, center=False, min_periods=1).median()\n",
    "    #median_120day = player_df.drop('date_game', axis=1).rolling(window=120, center=False, min_periods=1).median()\n",
    " \n",
    "    this_df = pd.concat([mean_3day, mean_10day, mean_30day, mean_60day, mean_90day, mean_120day,\n",
    "                        median_3day, median_10day, median_30day, median_60day, median_90day,\n",
    "                        median_120day], axis=1)\n",
    "    \n",
    "    this_df['player'] = player\n",
    "\n",
    "    this_df.to_csv('../data/player_rolling/'+player.replace(' ', '_')+'.csv')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (dirpath, dirnames, filenames) in os.walk('../data/player_dfs/'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any idea why 16,567 files were made, but there are 16,566 players?\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = filenames # [:3] for testing\n",
    "\n",
    "with open('../data/rolling_df.csv', 'wb') as output:\n",
    "    for filename in f:\n",
    "        with open('../data/player_dfs/'+filename, 'rb') as _input:\n",
    "            for i, line in enumerate(_input):\n",
    "                if i == 0:\n",
    "                    continue       \n",
    "                #print(line) # for testing\n",
    "                output.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling_df = pd.read_csv('../data/rolling_df.csv', skiprows=1, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.Series(stats)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ewm_cols = []\n",
    "for i in ['01', '03', '05', '07', '09', '10']:\n",
    "    for j in stats.drop(18):\n",
    "        ewm_cols.append('ewm'+j+'_'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_cols.insert(0, 'date_game')\n",
    "ewm_cols.append('player')\n",
    "len(ewm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling_df.columns = ewm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific to rolling mean and rolling median\n",
    "#rolling_df_cols = all_rolling\n",
    "#rolling_df_cols.insert(0, 'date_game')\n",
    "#rolling_df_cols.append('player')\n",
    "#len(rolling_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specific to rolling mean and rolling median\n",
    "#rolling_df.columns = rolling_df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling_df.set_index(['player', 'date_game'], drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_df = df.join(rolling_df, how='left', on=['player', 'date_game'], rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer Defender Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "school_list = school_df['School']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game_dates = df['date_game'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST!!!\n",
    "game_dates = '2010-11-08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for m in game_dates:\n",
    "    for n in school_list:    \n",
    "        date_mask = m\n",
    "        school_mask = n\n",
    "\n",
    "        df_myteam = df[(df['date_game']==date_mask) & (df['school_id']==school_mask)]\n",
    "        df_myteam = df_myteam.sort_values(['gs', 'mp'], ascending=False)\n",
    "\n",
    "        opp_school = list(df_myteam['opp_id'])[0]\n",
    "\n",
    "        df_opp = df[(df['date_game']==date_mask) & (df['school_id']==opp_school)]\n",
    "        df_opp = df_opp.sort_values(['gs', 'mp'], ascending=False)\n",
    "\n",
    "        largest = min([len(df_opp), len(df_myteam)])\n",
    "\n",
    "        df_myteam = df_myteam[0:largest]\n",
    "        df_opp = df_opp[0:largest]\n",
    "\n",
    "        my_team_index = df_myteam.index\n",
    "        matchup_index = []\n",
    "\n",
    "        opp_pos_list = df_opp['pos']\n",
    "\n",
    "        for i in df_myteam['pos']:\n",
    "            if i == 'PG':\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'PG':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'SG':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'G':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "\n",
    "            if i == 'SG':\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'SG':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'PG':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'G':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break  \n",
    "\n",
    "            if i == 'SF':\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'SF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'PF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'F':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "\n",
    "            if i == 'PF':\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'PF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'SF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'C':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'F':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "\n",
    "            if i == 'C':\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'C':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'PF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "\n",
    "            if i == 'G':\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'PG':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'SG':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'G':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'SF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "\n",
    "            if i == 'F':\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'PF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'SF':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "                for j in df_opp['pos'].index:\n",
    "                    if df_opp['pos'][j] == 'F':\n",
    "                        matchup_index.append(j)\n",
    "                        df_opp['pos'].drop(j, inplace=True)\n",
    "                        break\n",
    "            try:\n",
    "                matchup_index.append(df_opp['pos'].index[0])\n",
    "                df_opp['pos'].drop(df_opp['pos'].index[0], inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "        df.merge()\n",
    "        # Do a thing that appends select cols to the right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specific to rolling mean and rolling median\n",
    "#all_rolling.append('pts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ewm_cols.append('pts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = joined_df.dropna()[ewm_cols].drop(['date_game', 'player'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Come back to set X to drop just pts and 'Unnamed:0'\n",
    "\n",
    "#X = test_df.drop(['pts'], axis=1)\n",
    "X = test_df.drop('pts', axis=1)\n",
    "y = test_df['pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss = StandardScaler()\n",
    "#ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression(normalize=True)\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(linreg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = linreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "plt.scatter(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_df = joined_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = orig_df[['school_id', 'date_game', 'pts', 'preds']].groupby(['school_id', 'date_game']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plt.scatter(temp['pts'], temp['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['pts'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp['mean'] = temp['pts'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp['pts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_score = np.full(86849, temp['pts'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_scores = temp['pts'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(real_scores, mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(real_scores, mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(real_scores, temp['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(real_scores, temp['preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(real_scores, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(real_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(temp['pts'].values))\n",
    "print(len(mean_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby(['school_id', 'date_game']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = joined_df.loc['Grayson Allen'][['mp','pts', 'ewmpts_05', 'ewmgame_score_05', 'date_game']].sort_values('date_game')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "plt.plot(test['pts'])\n",
    "#plt.plot(test['mp'])\n",
    "plt.plot(test['ewmgame_score_05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ewm_test = player_df.drop('date_game', axis=1).ewm(alpha = 0.5).mean().head()\n",
    "ewm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewm_test.shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.groupby(['school_id', 'season']).sum().sort_values('pts', ascending=False)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
