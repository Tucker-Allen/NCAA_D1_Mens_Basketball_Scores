{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell was hosted on AWS and ran as a .py file\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "col_list = ['player', 'pos', 'date_game', 'school_id', 'opp_id', 'game_result', 'gs', 'mp', 'fg', 'fga', 'fg_pct', \n",
    "                'fg2', 'fg2a', 'fg2_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', \n",
    "                'stl', 'blk', 'tov', 'pf', 'pts', 'game_score']\n",
    "\n",
    "stat_list = ['gs', 'mp', 'fg', 'fga', 'fg_pct', 'fg2', 'fg2a', 'fg2_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct',\n",
    "                'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'game_score']\n",
    "\n",
    "df = pd.DataFrame(columns=col_list)\n",
    "\n",
    "offset = str(0)\n",
    "while int(offset) < 909000: # Change to 909,000\n",
    "    \n",
    "    URL = \"https://www.sports-reference.com/cbb/play-index/pgl_finder.cgi?request=1&match=game&year_min=2011&year_max=2018&school_id=&opp_id=&person_id=&is_range=N&game_type=A&game_month=&game_location=&game_result=&game_num_min=&game_num_max=&is_starter=&pos_is_g=Y&pos_is_gf=Y&pos_is_f=Y&pos_is_fg=Y&pos_is_fc=Y&pos_is_c=Y&pos_is_cf=Y&c1stat=&c1comp=&c1val=&c2stat=&c2comp=&c2val=&c3stat=&c3comp=&c3val=&c4stat=&c4comp=&c4val=&is_dbl_dbl=&is_trp_dbl=&order_by=pts&order_by_asc=&offset=\"+offset\n",
    "    response = requests.get(URL)\n",
    "    print(response.status_code)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    names = []\n",
    "    pos = []\n",
    "    dates = []\n",
    "    school = []\n",
    "    opp = []\n",
    "    result = []\n",
    "\n",
    "    this_df = pd.DataFrame(columns=col_list)\n",
    "\n",
    "    td_names = soup.find_all('td', {'data-stat':'player'})\n",
    "    for element in td_names:\n",
    "        td_ref = element.find('a')\n",
    "        try:\n",
    "            names.append(td_ref.text)\n",
    "        except:\n",
    "            names.append(np.nan)\n",
    "\n",
    "    td_pos = soup.find_all('td', {'data-stat':'pos'})\n",
    "    for element in td_pos:\n",
    "        try:\n",
    "            pos.append(element.text)\n",
    "        except:\n",
    "            pos.append(np.nan)\n",
    "\n",
    "    td_date = soup.find_all('td', {'data-stat':'date_game'})\n",
    "    for element in td_date:\n",
    "        td_ref = element.find('a')\n",
    "        try:\n",
    "            dates.append(td_ref.text)\n",
    "        except:\n",
    "            dates.append(np.nan)\n",
    "\n",
    "    td_school = soup.find_all('td', {'data-stat':'school_id'})\n",
    "    for element in td_school:\n",
    "        td_ref = element.find('a')\n",
    "        try:\n",
    "            school.append(td_ref.text)   \n",
    "        except:\n",
    "            school.append(np.nan)\n",
    "\n",
    "    td_opp = soup.find_all('td', {'data-stat':'opp_id'})\n",
    "    for element in td_opp:\n",
    "        td_ref = element.find('a')\n",
    "        try:\n",
    "            opp.append(td_ref.text)\n",
    "        except:\n",
    "            opp.append(np.nan)\n",
    "\n",
    "    td_result = soup.find_all('td', {'data-stat':'game_result'})\n",
    "    for element in td_result:\n",
    "        try:\n",
    "            result.append(element.text)\n",
    "        except:\n",
    "            result.append(np.nan)\n",
    "\n",
    "    this_df['player'] = names\n",
    "    this_df['pos'] = pos\n",
    "    this_df['date_game'] = dates\n",
    "    this_df['school_id'] = school\n",
    "    this_df['opp_id'] = opp\n",
    "    this_df['game_result'] = result\n",
    "\n",
    "    for stat in stat_list:\n",
    "        i = 0\n",
    "        td_stat = soup.find_all('td', {'data-stat':stat})\n",
    "        for element in td_stat:\n",
    "            this_df.set_value(i, stat, element.text)\n",
    "            i += 1\n",
    "    \n",
    "    df = pd.concat([df, this_df])\n",
    "    \n",
    "    if int(offset)%100000==0: # Change to 100,000\n",
    "        print('Writing to offset...', offset)\n",
    "        df.to_csv('./offset_'+offset)\n",
    "        \n",
    "    if int(offset)==909000: # Change to 909,000\n",
    "        print('Writing to offset...', offset)\n",
    "        df.to_csv('./offset_'+offset)\n",
    "    \n",
    "    time.sleep(10)\n",
    "    offset = str(int(offset)+100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This cell was a one-time run\n",
    "stat_year = 2010\n",
    "col_list = ['School', 'WinLossPct', 'SRS', 'SOS', 'Year']\n",
    "school_df = pd.DataFrame(columns=col_list)\n",
    "\n",
    "for i in range(2010,2019, 1):\n",
    "    \n",
    "    schools = []\n",
    "    winlosspct = []\n",
    "    srs = []\n",
    "    sos = []\n",
    "    stat_year = i\n",
    "    \n",
    "    this_df = pd.DataFrame(columns=col_list)\n",
    "    \n",
    "    URL = 'https://www.sports-reference.com/cbb/seasons/'+str(stat_year)+'-school-stats.html'\n",
    "    response = requests.get(URL)\n",
    "    print(response.status_code)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "     \n",
    "    td_schools = soup.find_all('td', {'data-stat':'school_name'})\n",
    "    for element in td_schools:\n",
    "        td_ref = element.find('a')\n",
    "        try:\n",
    "            schools.append(td_ref.text)\n",
    "        except:\n",
    "            schools.append(np.nan)\n",
    "            \n",
    "    td_winloss = soup.find_all('td', {'data-stat':'win_loss_pct'})\n",
    "    for element in td_winloss:\n",
    "        try:\n",
    "            winlosspct.append(element.text)\n",
    "        except:\n",
    "            winlosspct.append(np.nan)\n",
    "            \n",
    "    td_srs = soup.find_all('td', {'data-stat':'srs'})\n",
    "    for element in td_srs:\n",
    "        try:\n",
    "            srs.append(element.text)\n",
    "        except:\n",
    "            srs.append(np.nan)\n",
    "\n",
    "    td_sos = soup.find_all('td', {'data-stat':'sos'})\n",
    "    for element in td_sos:\n",
    "        try:\n",
    "            sos.append(element.text)\n",
    "        except:\n",
    "            sos.append(np.nan)\n",
    "            \n",
    "    this_df['School'] = schools\n",
    "    this_df['WinLossPct'] = winlosspct\n",
    "    this_df['SRS'] = srs\n",
    "    this_df['SOS'] = sos\n",
    "    this_df['Year'] = stat_year\n",
    "    \n",
    "    school_df = pd.concat([school_df, this_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
